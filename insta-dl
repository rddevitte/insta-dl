#!/usr/bin/env python3

import argparse
import fileinput
import json
from json.decoder import JSONDecodeError
import re
import requests
import sys
from urllib.parse import urlparse
import wget


def add_into(x, y):
    for f in y.items():
        p, q = f
        if p not in x:
            x[p] = q
        else:
            x[p] += q


def download_media(media_list):
    error = 0

    try:
        if not media_list:
            raise Exception('Media URLs list is empty.')

        for medias in media_list.items():
            username, media_urls = medias
            filecount = 0

            for url in media_urls:
                fname = re.search(r'^\/.+\/(.+)$',
                                  urlparse(url).path).group(1)

                print('Downloading file %d of %d...' %
                      (filecount + 1, len(media_urls)))

                file = wget.download(url, username + '.' + fname)
                filecount += 1
                print()

            print("Done downloading %d file(s) from user '%s'!" %
                  (filecount, username))

    except Exception as e:
        print(e, file=sys.stderr)
        error = 1

    return error


def parse_ig_json(content):
    urls = []

    # "Old" syntax
    if 'graphql' in content:
        insta = content['graphql']['shortcode_media']

        if 'edge_sidecar_to_children' not in insta:
            if insta['is_video']:
                url = insta['video_url']
            else:
                url = insta['display_resources'][2]['src']

            urls.append(url)
        else:
            for multiple in insta['edge_sidecar_to_children']['edges']:
                if multiple['node']['is_video']:
                    url = multiple['node']['video_url']
                else:
                    url = multiple['node']['display_resources'][2]['src']

                urls.append(url)

        username = insta['owner']['username']

    # "New" syntax
    elif 'items' in content:
        insta = content['items'][0]

        if 'carousel_media_count' not in insta:
            if insta['media_type'] == 1:
                url = insta['image_versions2']['candidates'][0]['url']
            elif insta['media_type'] == 2:
                url = insta['video_versions'][0]['url']

            urls.append(url)
        else:
            count = insta['carousel_media_count']

            for i in range(count):
                if insta['carousel_media'][i]['media_type'] == 1:
                    url = insta['carousel_media'][i]['image_versions2']['candidates'][0]['url']
                elif insta['carousel_media'][i]['media_type'] == 2:
                    url = insta['carousel_media'][i]['video_versions'][0]['url']

                urls.append(url)

        username = insta['user']['username']

    else:
        raise Exception(
            "JSON content seems not to be from IG (or has an yet unsupported syntax)!")

    return {username: urls}


def get_media_list_from_url(url):
    url_pattern = r'(https:\/\/www\.instagram\.com\/(?:p|reel|tv)\/[a-zA-Z0-9_-]{11}\/).*'
    user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36'
    headers = {'User-Agent': user_agent}
    media_list = {}

    try:
        u = re.findall(url_pattern, url)

        if len(u) < 1:
            raise Exception(
                "URL '%s' doesn't match IG media URL format!" % url)

        graphql_url = u[0] + '?__a=1'
        response = requests.get(graphql_url, headers=headers)

        if response.status_code != 200:
            raise Exception(
                "Received HTTP status code %d when trying to fetch from URL '%s'!" %
                (response.status_code, url))

        json_content = json.loads(response.content)
        media_list = parse_ig_json(json_content)

    except JSONDecodeError:
        print('Content is not in JSON format!', file=sys.stderr)
        print(
            'You probably must be logged in to fetch JSON content from the URL.',
            file=sys.stderr)

    except Exception as e:
        print(e, file=sys.stderr)

    return media_list


def get_media_list_from_json_file(filename):
    media_urls = {}

    try:
        with open(filename, 'r') as file:
            buf = file.read()
            json_content = json.loads(buf)
            media_urls = parse_ig_json(json_content)

    except IOError:
        print("Seems file '%s' doesn't exist or has restricted permissions!" %
              filename, file=sys.stderr)

    except JSONDecodeError:
        print("Content of file '%s' is not in JSON format!" %
              filename, file=sys.stderr)

    except Exception as e:
        print('Unexpected exception:', e, file=sys.stderr)

    return media_urls


def get_media_list_from_url_list(url_list):
    media_list = {}

    for url in url_list:
        add_into(media_list, get_media_list_from_url(url))

    return media_list


def get_ig_urls_from_filelist(filename):
    urls = []

    try:
        with open(filename, 'r') as file:
            while line := file.readline().rstrip():
                urls.append(line)

    except IOError:
        print("Seems file '%s' doesn't exist or has restricted permissions!" %
              filename, file=sys.stderr)

    except Exception as e:
        print('Unexpected exception:', e, file=sys.stderr)

    return urls


def get_ig_urls_from_stdin():
    urls = []

    try:
        for url in fileinput.input():
            urls.append(url.rstrip('\r').rstrip('\n'))

    except KeyboardInterrupt:
        print('\nReading from stdin interrupted')

    except Exception as e:
        print('Unexpected exception:', e, file=sys.stderr)

    return urls


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Download Instagram media')
    parser.add_argument(
        '-u', '--url', help='Instagram page URL of the media', type=str)
    parser.add_argument(
        '-j', '--json',
        help='File containing media data in JSON format (GraphQL)', type=str)
    parser.add_argument(
        '-l',
        '--list',
        help="Text file containing a list of IG URL's",
        type=str)
    args = parser.parse_args()

    if args.url is None and args.json is None and args.list is None:
        print('Neither IG URL nor JSON file nor list of URLs provided!')
        print('Accepting URL(s) from standard input...')
        return_code = download_media(
            get_media_list_from_url_list(get_ig_urls_from_stdin()))
    else:
        return_code = 0

        if args.url is not None:
            return_code += download_media(get_media_list_from_url(args.url))
        if args.json is not None:
            return_code += download_media(
                get_media_list_from_json_file(args.json))
        if args.list is not None:
            return_code += download_media(get_media_list_from_url_list(
                get_ig_urls_from_filelist(args.list)))

    sys.exit(return_code)
